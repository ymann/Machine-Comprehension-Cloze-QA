{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess+base_model+train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymann/Machine-Comprehension-Cloze-QA/blob/master/Preprocess%2Bbase_model%2Btrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CNS4OZXxMZ-A",
        "outputId": "602b9c34-eea5-4b26-f419-df11f7295b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "cell_type": "code",
      "source": [
        "#Download and unzip files\n",
        "!pip3 install scikit-learn\n",
        "!pip3 install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.20.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.2)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.134)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.134 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.134)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.134->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.134->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RpUkUwIf0RQU",
        "colab_type": "code",
        "outputId": "79d80062-0207-4bb8-8e03-56a70f1752c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "! sudo apt-get install unzip\n",
        "! wget http://seas.upenn.edu/~branlin/cnn.tgz \n",
        "! tar -xzf cnn.tgz\n",
        "# ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# ! unzip glove.6B.zip\n",
        "# ! touch word2vec.txt\n",
        "  \n",
        "  \n",
        "# Mount your google drive. \n",
        "# Use this to save your PyTorch model for submission\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "# !mkdir /content/gdrive/My\\ Drive/gloves\n",
        "# #Test drive access. \n",
        "# #You should have a test.txt under a new folder cis530_hw6 in your Google drive\n",
        "# with open('/content/gdrive/My Drive/gloves/', 'w') as f:\n",
        "#   f.write('This is a test!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "--2019-04-25 17:38:56--  http://seas.upenn.edu/~branlin/cnn.tgz\n",
            "Resolving seas.upenn.edu (seas.upenn.edu)... 158.130.68.91\n",
            "Connecting to seas.upenn.edu (seas.upenn.edu)|158.130.68.91|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.seas.upenn.edu/~branlin/cnn.tgz [following]\n",
            "--2019-04-25 17:38:57--  https://www.seas.upenn.edu/~branlin/cnn.tgz\n",
            "Resolving www.seas.upenn.edu (www.seas.upenn.edu)... 158.130.68.91, 2607:f470:8:64:5ea5::9\n",
            "Connecting to www.seas.upenn.edu (www.seas.upenn.edu)|158.130.68.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217447312 (207M) [application/x-gzip]\n",
            "Saving to: ‘cnn.tgz’\n",
            "\n",
            "cnn.tgz             100%[===================>] 207.37M  79.2MB/s    in 2.6s    \n",
            "\n",
            "2019-04-25 17:38:59 (79.2 MB/s) - ‘cnn.tgz’ saved [217447312/217447312]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eb_DrywYHsea",
        "colab_type": "code",
        "outputId": "f3178b3b-42b5-4f8b-a836-ad348dc0c85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "cell_type": "code",
      "source": [
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torch torchvision\n",
        "  \n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.1 from https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MEKp_8FConPP",
        "colab_type": "code",
        "outputId": "292cdfc5-094e-4944-faae-675a070a3ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cis700/hw1-release.git\n",
        "!mv hw1-release/helper.py .\n",
        "!rm -rf hw1-release/\n",
        "!rm -rf hw1/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hw1-release'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 26 (delta 6), reused 23 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (26/26), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vlW8S1bMoaRP",
        "colab_type": "code",
        "outputId": "01be2d1d-5c33-4b67-8574-51e4160d3127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './logs'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "!if [ -f ngrok ] ; then echo \"Ngrok already installed\" ; else wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip > /dev/null 2>&1 && unzip ngrok-stable-linux-amd64.zip > /dev/null 2>&1 ; fi\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ngrok already installed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h68zP3nhohEM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LS3Mgx2Hojq4",
        "colab_type": "code",
        "outputId": "29f51455-d0e3-4881-a20d-8817f7707477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print('Tensorboard Link: ' +str(json.load(sys.stdin)['tunnels'][0]['public_url']))\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorboard Link: https://49ddcd6d.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jD-g0Ay3LUjv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec, get_glove_info\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oFptVk1Pv03f",
        "colab_type": "code",
        "outputId": "4ebaad4a-a432-4321-b34b-ac62c2ecf1fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile questions.py\n",
        "import torch\n",
        "import os\n",
        "\n",
        "class QuestionDataset(torch.utils.data.Dataset):\n",
        "  \n",
        "  def __init__(self, root_dir):\n",
        "    self.root_dir = root_dir\n",
        "    self.files = os.listdir(os.path.join(os.getcwd(), root_dir))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if idx % 10000 == 0:\n",
        "      print (idx)\n",
        "    with open(os.path.join(self.root_dir, self.files[idx]), 'r') as f:\n",
        "      s = f.read()\n",
        "    \n",
        "    lines = s.split('\\n')\n",
        "    doc = lines[2]\n",
        "    tokens = doc.split()\n",
        "    query = lines[4]\n",
        "    query_tokens = query.split()\n",
        "    answer = lines[6]\n",
        "#     ent = [tuple(i.split(\":\")) for i in lines[8:]]\n",
        "#     entities = {i:j for i,j in ent}\n",
        "    return (tokens, query_tokens, answer)\n",
        "\n",
        "train_set = QuestionDataset(\"cnn/questions/training\")\n",
        "test_set = QuestionDataset(\"cnn/questions/test\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting questions.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dZ0Ayd6xwl61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set = QuestionDataset(\"cnn/questions/training\")\n",
        "test_set = QuestionDataset(\"cnn/questions/test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oL3I4KoIRgp3",
        "colab_type": "code",
        "outputId": "aeadcdce-93eb-4ac4-c010-39e645dd8bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# model.get_vector('ryan')\n",
        "# get_glove_info(glove_file)\n",
        "len(test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "rQcBYggu3WWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(train_set[0][0])\n",
        "glove_file = datapath('/content/glove.6B.50d.txt')\n",
        "tmp_file = get_tmpfile(\"./word2vec.txt\")\n",
        "glove2word2vec(glove_file, tmp_file)\n",
        "em = KeyedVectors.load_word2vec_format(tmp_file)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tCDyDuDwyxoL",
        "colab_type": "code",
        "outputId": "bd6b846d-7a16-4095-9a74-80fbbca11e05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile BiLSTM.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, emsize, hidden_dim, vocab_size, num_entities, batch_size, dropout=0.2):\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.emsize = emsize\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_init = (torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad=True).to(device)), (torch.zeros(2, self.batch_size, self.hidden_dim, requires_grad=True).to(device))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.start_symbols = torch.ones(10, 1).long().to(device)\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, num_entities)\n",
        "        # Vocabulary embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, emsize)\n",
        "        # RNN Encoder and Decoder\n",
        "        self.lstm = nn.LSTM(input_size=emsize,\n",
        "                               hidden_size=hidden_dim,\n",
        "                               dropout=dropout,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=True)\n",
        "        \n",
        "    def forward(self, dq):\n",
        "      padded = rnn_utils.pad_sequence(dq).transpose(1, 0)\n",
        "      lengths = torch.Tensor([len(c) for c in dq])\n",
        "      embedded = self.embedding(padded)\n",
        "     #pack sequence\n",
        "      packed_embed = pack(embedded, lengths, batch_first=True)\n",
        "      packed_output, (hidden, cell) = self.lstm(packed_embed)\n",
        "\n",
        "      #unpack sequence\n",
        "      output, input_sizes = unpack(packed_output, batch_first=True)\n",
        "        \n",
        "      final_output = output[torch.arange(lengths.size()[0], out=torch.LongTensor()), lengths.long() - 1]\n",
        "      return self.fc1(final_output)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting BiLSTM.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9draJ4u-dhIn",
        "colab_type": "code",
        "outputId": "0b6fc8eb-d970-459e-f0e3-caed50cbce72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "cell_type": "code",
      "source": [
        "# Computing vocabulary size\n",
        "words = set()\n",
        "entities = set()\n",
        "for d, q, _ in train_set:\n",
        "  thing = set(d + q)\n",
        "  entity_things = {i for i in thing if i.startswith('@entity')}\n",
        "  words = words.union(thing)\n",
        "  entities = entities.union(entity_things)\n",
        "  del thing\n",
        "  del entity_things\n",
        "for d, q, _ in test_set:\n",
        "  thing = set(d + q)\n",
        "  entity_things = {i for i in thing if i.startswith('@entity')}\n",
        "  words.union(thing)\n",
        "  entities = entities.union(entity_things)\n",
        "  del thing\n",
        "  del entity_things\n",
        "print(len(words))\n",
        "print(len(entities))\n",
        "# num_vocab = set().union(*[set(d + q) for d, q, _ in train_set]).size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n",
            "140000\n",
            "150000\n",
            "160000\n",
            "170000\n",
            "180000\n",
            "190000\n",
            "200000\n",
            "210000\n",
            "220000\n",
            "230000\n",
            "240000\n",
            "250000\n",
            "260000\n",
            "270000\n",
            "280000\n",
            "290000\n",
            "300000\n",
            "310000\n",
            "320000\n",
            "330000\n",
            "340000\n",
            "350000\n",
            "360000\n",
            "370000\n",
            "380000\n",
            "0\n",
            "118497\n",
            "584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r_vMpjWuhABN",
        "colab_type": "code",
        "outputId": "5ce3097c-fd30-4e65-b16d-96665ae5c27e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "for d, q, _ in test_set:\n",
        "  thing = set(d + q)\n",
        "  words.union(*thing)\n",
        "  del thing\n",
        "print(len(words))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Y3H4lztTLN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "emsize = 50\n",
        "hidden_dim = 75\n",
        "vocab_size = 118497 + 1 # for the delimiter\n",
        "num_entities = 584\n",
        "batch_size = 50\n",
        "num_epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rj5F7nq8yHOt",
        "colab_type": "code",
        "outputId": "d6564d31-05ac-4977-9125-8bf7cfd38575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile foo.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phraser, Phrases\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec, get_glove_info\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from questions import train_set, test_set\n",
        "from BiLSTM import BiLSTM\n",
        "import datetime\n",
        "from helper import Logger\n",
        "\n",
        "emsize = 50\n",
        "hidden_dim = 75\n",
        "vocab_size = 118497 + 1 # for the delimiter\n",
        "num_entities = 584\n",
        "batch_size = 50\n",
        "num_epochs = 5\n",
        "\n",
        "logger = Logger('./logs/run_' + str(datetime.datetime.now()))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = BiLSTM(emsize, hidden_dim, vocab_size, num_entities, batch_size).to(device)\n",
        "num_words_indexed = 2\n",
        "num_entities_indexed = 0\n",
        "vocab_dict = {'|||': 1} # word : index\n",
        "entity_dict = dict()\n",
        "\n",
        "def index_strings(strings):\n",
        "  '''strings is a list of strings'''\n",
        "  l = []\n",
        "  global num_words_indexed\n",
        "  global num_entities_indexed\n",
        " \n",
        "  for i in strings:\n",
        "    if i in vocab_dict:\n",
        "      l.append(vocab_dict[i])\n",
        "    else:\n",
        "      vocab_dict[i] = num_words_indexed\n",
        "      num_words_indexed += 1\n",
        "    if i.startswith('@entity'):\n",
        "      if i not in entity_dict:\n",
        "        entity_dict[i] = num_entities_indexed\n",
        "        num_entities_indexed += 1\n",
        "  return l\n",
        "\n",
        "def train_model(model, train_data):\n",
        "  global entities\n",
        "  step = 0\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "  test_loader = DataLoader(train_set, batch_size = batch_size, collate_fn=lambda x : x, shuffle=True)\n",
        "  model = model.to(device)\n",
        "  loss_criterion = criterion.to(device)\n",
        "  for epoch in range(num_epochs):\n",
        "    # (batch_d,batch_q,batch_label)\n",
        "    data_iter = iter(test_loader)\n",
        "    for i, thing in enumerate(data_iter):\n",
        "      sentence_converted = [(index_strings(d), index_strings(q), entity_dict[e]) for d, q, e in thing]\n",
        "      dq = [torch.Tensor(d + [1] + q).long().to(device) for d, q, e in sentence_converted]\n",
        "      lengths = torch.Tensor([len(c) for c in dq])\n",
        "      lengths, idx = lengths.sort(0, descending=True)\n",
        "      dq = [dq[i] for i in idx]\n",
        "      expected = torch.Tensor([e for _, _, e in sentence_converted]).flatten().long().to(device)\n",
        "      expected = expected[idx]\n",
        "      output = model(dq)\n",
        "      \n",
        "      entities = [sorted(list(set([entity_dict[e] for e in d if e.startswith(\"@entity\")]))) for d, _, _ in thing]\n",
        "      entities = [entities[i] for i in idx]\n",
        "      \n",
        "      def calculate_loss(i):\n",
        "        t = output[i]\n",
        "        predictions = t[entities[i]]\n",
        "        index_of_correct = entities[i].index(expected[i].item())\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        return criterion(predictions.unsqueeze(0), torch.Tensor([index_of_correct]).long().to(device))\n",
        "      \n",
        "      loss = sum([calculate_loss(i) for i in range(len(thing))]) / len(thing)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "#       loss = loss_criterion(output, expected)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      logger.scalar_summary(\"loss\", loss.item(), step+1)\n",
        "      step += 1\n",
        "\n",
        "train_model(model, test_set)\n",
        "\n",
        "def test_model(model, test_data):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    test_loader = DataLoader(test_set, batch_size = 1, collate_fn=lambda x : x)\n",
        "    for i, thing in enumerate(test_loader):\n",
        "      sentence_converted = [(index_strings(d), index_strings(q), entity_dict[e]) for d, q, e in thing]\n",
        "      dq = [torch.Tensor(d + [1] + q).long().to(device) for d, q, e in sentence_converted]\n",
        "      lengths = torch.Tensor([len(c) for c in dq])\n",
        "      lengths, idx = lengths.sort(0, descending=True)\n",
        "      dq = [dq[i] for i in idx]\n",
        "      expected = torch.Tensor([e for _, _, e in sentence_converted]).flatten().long().to(device)\n",
        "      expected = expected[idx]\n",
        "      output = model(dq)\n",
        "      \n",
        "      entities = [sorted(list(set([entity_dict[e] for e in d if e.startswith(\"@entity\")]))) for d, _, _ in thing]\n",
        "      entities = [entities[i] for i in idx]\n",
        "      \n",
        "      predictions = output[0][entities[0]]\n",
        "      index_of_correct = entities[0].index(expected[0].item())\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "#       return criterion(predictions.unsqueeze(0), torch.Tensor([index_of_correct]).long().to(device))\n",
        "      \n",
        "      _, argmax = torch.max(predictions, 0)\n",
        "      print(argmax, len(predictions))\n",
        "      if (argmax.item() == index_of_correct):\n",
        "        correct += 1\n",
        "      total += 1\n",
        "  return correct / total\n",
        "      \n",
        "print(test_model(model, test_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting foo.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kUbR9XgB7g7g",
        "colab_type": "code",
        "outputId": "0e99b4d1-282e-4a72-c8fb-67cde9b8dede",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "! export CUDA_LAUNCH_BLOCKING=1; python3 foo.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
            "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
            "Traceback (most recent call last):\n",
            "  File \"foo.py\", line 16, in <module>\n",
            "    from questions import train_set, test_set\n",
            "ModuleNotFoundError: No module named 'questions'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "94wnHXKlj6pC",
        "colab_type": "code",
        "outputId": "dcb9e16f-0025-491e-8957-ebdcd71c3977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3764
        }
      },
      "cell_type": "code",
      "source": [
        "def test_model(model, test_data):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    test_loader = DataLoader(test_set, batch_size = 1, collate_fn=lambda x : x)\n",
        "    for i, thing in enumerate(test_loader):\n",
        "      sentence_converted = [(index_strings(d), index_strings(q), int(e[7:])) for d, q, e in thing]\n",
        "      dq = [torch.Tensor(d + [1] + q).long().to(device) for d, q, e in sentence_converted]\n",
        "      lengths = torch.Tensor([len(c) for c in dq])\n",
        "      lengths, idx = lengths.sort(0, descending=True)\n",
        "      dq = [dq[i] for i in idx]\n",
        "      expected = torch.Tensor([e for _, _, e in sentence_converted]).flatten().long().to(device)\n",
        "      expected = expected[idx]\n",
        "      output = model(dq)\n",
        "      \n",
        "      entities = [sorted(list(set([int(e[7:]) for e in d if e.startswith(\"@entity\")]))) for d, _, _ in thing]\n",
        "      entities = [entities[i] for i in idx]\n",
        "      \n",
        "      predictions = output[0][entities[0]]\n",
        "      index_of_correct = entities[0].index(expected[0].item())\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "#       return criterion(predictions.unsqueeze(0), torch.Tensor([index_of_correct]).long().to(device))\n",
        "      \n",
        "      _, argmax = torch.max(predictions, 0)\n",
        "      print(argmax, len(predictions))\n",
        "      if (argmax.item() == index_of_correct):\n",
        "        correct += 1\n",
        "      total += 1\n",
        "  return correct / total\n",
        "      \n",
        "test_model(model, test_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "tensor(4, device='cuda:0') 31\n",
            "tensor(1, device='cuda:0') 37\n",
            "tensor(0, device='cuda:0') 20\n",
            "tensor(2, device='cuda:0') 14\n",
            "tensor(0, device='cuda:0') 56\n",
            "tensor(2, device='cuda:0') 30\n",
            "tensor(0, device='cuda:0') 8\n",
            "tensor(1, device='cuda:0') 47\n",
            "tensor(3, device='cuda:0') 13\n",
            "tensor(1, device='cuda:0') 15\n",
            "tensor(0, device='cuda:0') 10\n",
            "tensor(2, device='cuda:0') 15\n",
            "tensor(1, device='cuda:0') 13\n",
            "tensor(0, device='cuda:0') 16\n",
            "tensor(1, device='cuda:0') 34\n",
            "tensor(2, device='cuda:0') 29\n",
            "tensor(3, device='cuda:0') 40\n",
            "tensor(2, device='cuda:0') 21\n",
            "tensor(0, device='cuda:0') 57\n",
            "tensor(1, device='cuda:0') 15\n",
            "tensor(4, device='cuda:0') 20\n",
            "tensor(4, device='cuda:0') 10\n",
            "tensor(0, device='cuda:0') 21\n",
            "tensor(0, device='cuda:0') 30\n",
            "tensor(3, device='cuda:0') 34\n",
            "tensor(0, device='cuda:0') 27\n",
            "tensor(5, device='cuda:0') 21\n",
            "tensor(0, device='cuda:0') 11\n",
            "tensor(3, device='cuda:0') 22\n",
            "tensor(2, device='cuda:0') 10\n",
            "tensor(0, device='cuda:0') 12\n",
            "tensor(0, device='cuda:0') 22\n",
            "tensor(3, device='cuda:0') 19\n",
            "tensor(6, device='cuda:0') 29\n",
            "tensor(2, device='cuda:0') 16\n",
            "tensor(0, device='cuda:0') 13\n",
            "tensor(2, device='cuda:0') 24\n",
            "tensor(1, device='cuda:0') 22\n",
            "tensor(2, device='cuda:0') 15\n",
            "tensor(1, device='cuda:0') 17\n",
            "tensor(3, device='cuda:0') 40\n",
            "tensor(2, device='cuda:0') 27\n",
            "tensor(0, device='cuda:0') 14\n",
            "tensor(4, device='cuda:0') 19\n",
            "tensor(1, device='cuda:0') 32\n",
            "tensor(2, device='cuda:0') 12\n",
            "tensor(6, device='cuda:0') 23\n",
            "tensor(2, device='cuda:0') 8\n",
            "tensor(0, device='cuda:0') 26\n",
            "tensor(0, device='cuda:0') 17\n",
            "tensor(2, device='cuda:0') 22\n",
            "tensor(0, device='cuda:0') 57\n",
            "tensor(2, device='cuda:0') 7\n",
            "tensor(1, device='cuda:0') 33\n",
            "tensor(0, device='cuda:0') 27\n",
            "tensor(4, device='cuda:0') 20\n",
            "tensor(0, device='cuda:0') 13\n",
            "tensor(1, device='cuda:0') 15\n",
            "tensor(3, device='cuda:0') 11\n",
            "tensor(4, device='cuda:0') 42\n",
            "tensor(1, device='cuda:0') 11\n",
            "tensor(3, device='cuda:0') 37\n",
            "tensor(1, device='cuda:0') 16\n",
            "tensor(2, device='cuda:0') 22\n",
            "tensor(3, device='cuda:0') 22\n",
            "tensor(4, device='cuda:0') 9\n",
            "tensor(4, device='cuda:0') 24\n",
            "tensor(1, device='cuda:0') 22\n",
            "tensor(0, device='cuda:0') 56\n",
            "tensor(2, device='cuda:0') 27\n",
            "tensor(3, device='cuda:0') 92\n",
            "tensor(0, device='cuda:0') 24\n",
            "tensor(1, device='cuda:0') 13\n",
            "tensor(2, device='cuda:0') 34\n",
            "tensor(4, device='cuda:0') 17\n",
            "tensor(2, device='cuda:0') 17\n",
            "tensor(1, device='cuda:0') 12\n",
            "tensor(2, device='cuda:0') 22\n",
            "tensor(1, device='cuda:0') 21\n",
            "tensor(5, device='cuda:0') 56\n",
            "tensor(3, device='cuda:0') 15\n",
            "tensor(0, device='cuda:0') 46\n",
            "tensor(2, device='cuda:0') 43\n",
            "tensor(2, device='cuda:0') 7\n",
            "tensor(1, device='cuda:0') 30\n",
            "tensor(3, device='cuda:0') 25\n",
            "tensor(2, device='cuda:0') 8\n",
            "tensor(2, device='cuda:0') 23\n",
            "tensor(2, device='cuda:0') 12\n",
            "tensor(1, device='cuda:0') 31\n",
            "tensor(3, device='cuda:0') 45\n",
            "tensor(3, device='cuda:0') 16\n",
            "tensor(2, device='cuda:0') 17\n",
            "tensor(3, device='cuda:0') 14\n",
            "tensor(1, device='cuda:0') 32\n",
            "tensor(1, device='cuda:0') 25\n",
            "tensor(2, device='cuda:0') 7\n",
            "tensor(0, device='cuda:0') 24\n",
            "tensor(0, device='cuda:0') 19\n",
            "tensor(2, device='cuda:0') 14\n",
            "tensor(0, device='cuda:0') 45\n",
            "tensor(0, device='cuda:0') 33\n",
            "tensor(3, device='cuda:0') 22\n",
            "tensor(0, device='cuda:0') 18\n",
            "tensor(3, device='cuda:0') 15\n",
            "tensor(2, device='cuda:0') 9\n",
            "tensor(1, device='cuda:0') 22\n",
            "tensor(3, device='cuda:0') 45\n",
            "tensor(1, device='cuda:0') 12\n",
            "tensor(2, device='cuda:0') 18\n",
            "tensor(3, device='cuda:0') 39\n",
            "tensor(3, device='cuda:0') 19\n",
            "tensor(2, device='cuda:0') 44\n",
            "tensor(0, device='cuda:0') 25\n",
            "tensor(4, device='cuda:0') 10\n",
            "tensor(4, device='cuda:0') 27\n",
            "tensor(2, device='cuda:0') 32\n",
            "tensor(0, device='cuda:0') 21\n",
            "tensor(1, device='cuda:0') 9\n",
            "tensor(0, device='cuda:0') 30\n",
            "tensor(2, device='cuda:0') 13\n",
            "tensor(1, device='cuda:0') 6\n",
            "tensor(1, device='cuda:0') 18\n",
            "tensor(3, device='cuda:0') 20\n",
            "tensor(0, device='cuda:0') 15\n",
            "tensor(1, device='cuda:0') 44\n",
            "tensor(2, device='cuda:0') 17\n",
            "tensor(2, device='cuda:0') 81\n",
            "tensor(1, device='cuda:0') 8\n",
            "tensor(3, device='cuda:0') 7\n",
            "tensor(4, device='cuda:0') 18\n",
            "tensor(2, device='cuda:0') 15\n",
            "tensor(0, device='cuda:0') 23\n",
            "tensor(3, device='cuda:0') 29\n",
            "tensor(1, device='cuda:0') 18\n",
            "tensor(4, device='cuda:0') 9\n",
            "tensor(2, device='cuda:0') 21\n",
            "tensor(1, device='cuda:0') 13\n",
            "tensor(1, device='cuda:0') 23\n",
            "tensor(3, device='cuda:0') 17\n",
            "tensor(5, device='cuda:0') 21\n",
            "tensor(2, device='cuda:0') 43\n",
            "tensor(0, device='cuda:0') 17\n",
            "tensor(1, device='cuda:0') 14\n",
            "tensor(2, device='cuda:0') 45\n",
            "tensor(0, device='cuda:0') 15\n",
            "tensor(2, device='cuda:0') 13\n",
            "tensor(0, device='cuda:0') 27\n",
            "tensor(5, device='cuda:0') 52\n",
            "tensor(3, device='cuda:0') 40\n",
            "tensor(2, device='cuda:0') 11\n",
            "tensor(3, device='cuda:0') 17\n",
            "tensor(2, device='cuda:0') 15\n",
            "tensor(0, device='cuda:0') 21\n",
            "tensor(0, device='cuda:0') 14\n",
            "tensor(0, device='cuda:0') 10\n",
            "tensor(3, device='cuda:0') 21\n",
            "tensor(0, device='cuda:0') 23\n",
            "tensor(0, device='cuda:0') 52\n",
            "tensor(2, device='cuda:0') 18\n",
            "tensor(1, device='cuda:0') 15\n",
            "tensor(2, device='cuda:0') 27\n",
            "tensor(0, device='cuda:0') 5\n",
            "tensor(1, device='cuda:0') 9\n",
            "tensor(3, device='cuda:0') 40\n",
            "tensor(2, device='cuda:0') 30\n",
            "tensor(3, device='cuda:0') 12\n",
            "tensor(0, device='cuda:0') 30\n",
            "tensor(2, device='cuda:0') 15\n",
            "tensor(3, device='cuda:0') 13\n",
            "tensor(1, device='cuda:0') 30\n",
            "tensor(1, device='cuda:0') 13\n",
            "tensor(0, device='cuda:0') 59\n",
            "tensor(0, device='cuda:0') 36\n",
            "tensor(3, device='cuda:0') 22\n",
            "tensor(1, device='cuda:0') 14\n",
            "tensor(1, device='cuda:0') 36\n",
            "tensor(3, device='cuda:0') 10\n",
            "tensor(2, device='cuda:0') 18\n",
            "tensor(2, device='cuda:0') 13\n",
            "tensor(0, device='cuda:0') 24\n",
            "tensor(0, device='cuda:0') 16\n",
            "tensor(0, device='cuda:0') 38\n",
            "tensor(1, device='cuda:0') 17\n",
            "tensor(1, device='cuda:0') 39\n",
            "tensor(0, device='cuda:0') 8\n",
            "tensor(2, device='cuda:0') 13\n",
            "tensor(3, device='cuda:0') 28\n",
            "tensor(0, device='cuda:0') 21\n",
            "tensor(0, device='cuda:0') 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-f40dd838fb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-f40dd838fb0d>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_data)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence_converted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"@entity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-4707766fb95d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dq)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#       packed_embedded = pack(dq, text_lengths)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mpacked_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;31m#unpack sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 182\u001b[0;31m                            self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}